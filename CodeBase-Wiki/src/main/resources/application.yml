server:
  port: 8085
  tomcat:
    uri-encoding: UTF-8

spring:
  # Spring AI 配置
  ai:
    # 模型提供商选择: dashscope（阿里云，默认）| ollama（本地模型）| openai（OpenAI）
    provider: ${SPRING_AI_PROVIDER:dashscope}
    
    dashscope:
      api-key: ${DASHSCOPE_API_KEY:your-key}
      chat:
        options:
          model: ${DASHSCOPE_CHAT_MODEL:qwen-plus-latest}
      embedding:
        options:
          model: ${DASHSCOPE_EMBEDDING_MODEL:text-embedding-v4}
    
    # Ollama 配置（本地大模型）
    ollama:
      base-url: ${OLLAMA_BASE_URL:http://localhost:11434}
      chat:
        options:
          model: ${OLLAMA_CHAT_MODEL:qwen2.5-coder:14b}
          temperature: 0.7
      embedding:
        options:
          model: ${OLLAMA_EMBEDDING_MODEL:nomic-embed-text}
    
    # OpenAI 配置
    openai:
      api-key: ${OPENAI_API_KEY:your-openai-api-key}
      base-url: ${OPENAI_BASE_URL:https://api.openai.com}
      chat:
        options:
          model: ${OPENAI_CHAT_MODEL:gpt-4o}
          temperature: 0.7
      embedding:
        options:
          model: ${OPENAI_EMBEDDING_MODEL:text-embedding-3-small}
    memory:
      redis:
        host: ${REDIS_HOST:your-address}
        port: ${REDIS_PORT:6379}
        password: ${REDIS_PASSWORD:your-redis-password}
        timeout: ${REDIS_TIMEOUT:5000}
  application:
    name: CodeBase-Wiki
# Redis连接配置
  data:
    redis:
      host: ${REDIS_HOST:your-address}
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD:your-redis-password}
      timeout: ${REDIS_TIMEOUT:2000ms}
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 0

  datasource:
    url: jdbc:sqlite:data/codebasewiki_db.sqlite
    driver-class-name: org.sqlite.JDBC
    username: test
    password: test
    hikari:
      maximum-pool-size: 30        # 最大连接数
      minimum-idle: 5              # 最小空闲连接数
      connection-timeout: 30000    # 连接超时时间(ms)
      idle-timeout: 600000         # 空闲超时时间(ms)
      max-lifetime: 1800000        # 连接最大生存时间(ms)
  sql:
    init:
      schema-locations: classpath:schema.sql
      mode: always
      continue-on-error: true
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:your-address:9092}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      retries: 3
      acks: 1
      batch-size: 16384
      linger-ms: 5

    consumer:
      group-id: doc-generation-consumer-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      auto-offset-reset: earliest
      enable-auto-commit: false
      max-poll-records: 10
      properties:
        spring.json.trusted.packages: "com.way.queue.model"

# MyBatis-Plus 配置
mybatis-plus:
  mapper-locations: classpath*:/mapper/**/*.xml
  type-aliases-package: com.way.model.entity
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  global-config:
    db-config:
      logic-delete-field: deleted
      logic-delete-value: 1
      logic-not-delete-value: 0

# 日志输出配置
logging:
  level:
    root: INFO
    # Tool调用监控日志
    com.way.monitor: INFO
    com.way.llm.tool: DEBUG
    com.way.llm.service: INFO
  org:
    springframework:
      boot: error
  file:
    name: ./logs/codebasewiki.log
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"

# Elasticsearch配置
elasticsearch:
  uris: ${ELASTICSEARCH_URIS:http://your-address:9200}
  username: ${ELASTICSEARCH_USERNAME:elastic}
  password: ${ELASTICSEARCH_PASSWORD:your-elasticsearch-password}
  connection-timeout: 5000
  socket-timeout: 60000
  # 索引配置
  indices:
    code-chunks: "code_chunks_index"
    documents: "documents_index"
  # 代码解析服务配置
  code-parser:
    url: ${CODE_PARSER_URL:http://your-address:8566}
    timeout: 30000

# Feign配置
feign:
  client:
    config:
      memory-service:
        connectTimeout: 5000
        readTimeout: 10000
        loggerLevel: basic
  hystrix:
    enabled: false
  circuitbreaker:
    enabled: false

# 通知配置
notification:
  # 是否启用通知功能
  enabled: true
  # 启用的通知渠道
  channels:
    - feishu
    - dingtalk
  
  # 飞书配置
  feishu:
    enabled: ${FEISHU_ENABLED:true}
    # Wiki文档机器人
    wiki-webhook: ${FEISHU_WIKI_WEBHOOK:your-feishu-wiki-webhook}
    wiki-secret: ${FEISHU_WIKI_SECRET:your-feishu-wiki-secret}
    # 代码评审机器人
    review-webhook: ${FEISHU_REVIEW_WEBHOOK:your-feishu-review-webhook}
    review-secret: ${FEISHU_REVIEW_SECRET:your-feishu-review-secret}
  
  # 钉钉配置
  dingtalk:
    enabled: ${DINGTALK_ENABLED:true}
    # Wiki文档机器人
    wiki-webhook: ${DINGTALK_WIKI_WEBHOOK:your-dingtalk-wiki-webhook}
    wiki-secret: ${DINGTALK_WIKI_SECRET:your-dingtalk-wiki-secret}
    # 代码评审机器人
    review-webhook: ${DINGTALK_REVIEW_WEBHOOK:your-dingtalk-review-webhook}
    review-secret: ${DINGTALK_REVIEW_SECRET:your-dingtalk-review-secret}

# 项目配置
project:
  repository:
    # Git仓库克隆根目录
    base-path: ${GIT_REPOSITORY_BASE_PATH:D:\Code\repository}
  # Wiki文档生成配置
  wiki:
    prompt:
      # 目录生成prompt版本 (v1, v2, v3, v4, v5) - v5为优化版本，减少文档碎片化
      catalogue-version: v5
      # 文档生成prompt版本 (v1, v2, v3, v4) - v4为精简版本，基于dependent_files优化
      doc-version: v4
    # Kafka消息队列配置
    kafka:
      topics:
        doc-generation: "doc-generation-topic"
        doc-retry: "doc-generation-retry-topic"
        doc-dlq: "doc-generation-dlq"
      consumer:
        # 最大并发消费者数量
        max-concurrency: 2
        # 处理间隔(ms)
        process-interval: 2000
        # 最大重试次数
        max-retry: 3
        # 重试延迟(ms)
        retry-delay: 30000
    # 监控配置
    monitor:
      # 启用Tool Calling监控
      tool-calling: true
      # 记录详细的Tool调用信息
      tool-details: true



